## PointCloud experiments using Open3dML library and their KPConv and RandLANet Implementations
The ultimate goal is to make a benchmarking dataset. So it requires manual annotation of the points in the dataset. To  semi automate the annotation process, several models were tested, including KPConv (Kernel Point Convolution) Network and RandLANet (Random Sampling and an Effective Local Feature Aggregator). Both standalone implementations and Open3D-ML implementations were utilized. The goal was to implement a reliable model to streamline the labeling process.

Training and inference phases were quite difficult compared to previous experiments due to the size of the datasets and the long training and inference times. The major constraint was to stick with the local hardware instead of running the models on the cloud. System specs are:

CPU 	: AMD Ryzen 9 7950X (16 core processor ~ 4.5GHz - 5.7GHz)
RAM 	: 128GB
GPU	: NVIDIA GeForce RTX 4080 SUPER ~ 16GB GDDR6X
Env	: Windows 11 Pro (WSL with Ubuntu 22.04 LTS)

Regarding the first methodology, Kernel Point Convolution (KPConv) introduces a novel approach to process 3D point clouds using rigid and deformable kernel based convolutions. For the rigid version, there is a fixed set of dispositions that the model can select from, while for the deformable one, the initial configuration is random, and during training, the kernel can adapt to the local geometry of the input cloud. The kernel points are set within a local spherical neighborhood around each input point, each associated with a weight matrix. The convolution operation involves a weighted sum of transformed features, where the weights are determined by a correlation function based on the distances between input and kernel points. The kernel points can slightly deform to adapt to the local geometry. To handle varying point densities, the output is normalized. This approach is implemented in a deep network architecture with pooling, upsampling, and skip connections. The resulting model is trained and evaluated on various 3D point cloud tasks, demonstrating its effectiveness in capturing local geometric patterns while adapting to irregular spatial distributions.
In RandLANet, two major aspects are feature aggregation and random sampling. By employing random point sampling instead of more complex selection methods, it ensures significant computational and memory efficiency. However, to mitigate the loss of important features due to random sampling, RandLANet incorporates a novel local feature aggregation module. This module progressively expands the receptive field for each point, preserving intricate geometric details. The architecture features shared multilayer perceptrons (MLPs) that facilitate fast processing, capable of handling 1 million points in a single pass. By eliminating preprocessing steps like voxelization or graph construction, RandLANet achieves exceptional speed and accuracy across benchmarks such as Semantic3D and SemanticKITTI. The model is also integrated with pooling, upsampling, and skip connections, further enhancing its ability to capture detailed local structures and adapt to real time applications.
These models were selected because of their efficiency and the datasets they were used on for the experiments. Due to the similarity in class structure and object geometry compared to the IIIT Bangalore dataset, they are expected to facilitate ease and effectiveness in linear probing and fine tuning. For the training and inference, I used both original and Open3DML models (Specifically torch model; they provide tensorflow models as well)
